#!/bin/bash

# Takes any packages in the dir mounted at /output and adds them to the remote
# S3 repo bucket for the specified stage (main, beta, or test).

set -euxo pipefail

GPG_KEY_ID=${GPG_KEY_ID:-224D6386098ACF3B}
OUTPUT_DIR=${OUTPUT_DIR:-/output}
REPO_STAGE=${1:-test}


case $REPO_STAGE in
  main|beta|test) ;;
  *) echo "REPO_STAGE must be 'main', 'beta' or 'test'" >&2 && exit 1 ;;
esac

repo_dir="/repo/${REPO_STAGE}"
s3_bucket="s3://signalfx-agent-test-packages/rpms/signalfx-agent/$REPO_STAGE"

mkdir -p $repo_dir
aws s3 sync --delete $s3_bucket $repo_dir

for f in $(find $OUTPUT_DIR -name "*.rpm"); do
  base=$(basename $f)
  if [ -e $repo_dir/$base ]; then
    echo "RPM package $(basename $f) already exists in this repo.  If you want to overwrite it, please delete it from the repo first." >&2 && exit 2
  fi
  cp $f $repo_dir
  if [[ -z ${NO_SIGN-} ]]; then
    rpm \
     --define "_gpg_name $GPG_KEY_ID"  \
     --define "_gpg_path /root/.gnupg"  \
     --define '_signature gpg' \
     --define '__gpg_check_password_cmd /bin/true' \
     --addsign ${repo_dir}/$(basename $f)
  fi
done

cd $repo_dir
createrepo --no-database .

if [[ -z ${NO_SIGN-} ]]; then
  gpg2 --batch --yes --detach-sign --armor --default-key $GPG_KEY_ID --digest-algo SHA256 repodata/repomd.xml
fi

aws s3 sync --dryrun $repo_dir $s3_bucket

read -p "Do the above file updates to the s3 bucket seem correct? [y/N] "
[[ ! "$REPLY" =~ ^[Yy]$ ]] && echo "Cancelling upload" && exit 1

aws s3 sync $repo_dir $s3_bucket
